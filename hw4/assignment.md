In this assignment, you will spend roughly 8-10 hours exploring the gymnasium package. To install gymnasium, follow these instructions. For this assignment, you will be graded based on the documentation (lab notebook) you provide and answers to a few questions along the way, rather than reaching a particular end point with training a model. You are encouraged to ask questions and make suggestions to your classmates on the discussion board as you work through this assignment. 

Please turn in two things:
1. Your code. If you have just one or two files you may submit them directly, or you may instead point us towards a public git repo with your code. 

    - (a) At least one attempt at training an agent using Q-learning. A gridworld such as FrozenLake is a good place to start, though you may choose any gymnasium environment. 
    - (b) At least one attempt at training an agent using PPO. 

2. A pdf with:

    (a) "Notes to your future self". Think of this as a few pages in a lab notebook, where you document what you tried, whether it worked, and what else you would try in the future. While this is a note to yourself, please clean up the formatting enough that the teaching team can actually make sense of your notes. You may want to include code snippets in your notes. Include references with links to any online tutorials or other sources that you use. 

    (b) Answers to the following exercises. Please treat this as a learning opportunity and pause to understand your answers, rather than straight copy-pasting from a web search or chatbot. 
    
        i. In your own words, define these terms and explain how they relate to each other: Value, Reward, Quality. 

        ii. In pseudocode (and supplementary text if needed), define the Q-learning algorithm using a table. Now do the same thing, but for deep Q-learning using a neural network in place of a table. 

        iii. In pseudocode (and supplementary text if needed), define the PPO algorithm.  